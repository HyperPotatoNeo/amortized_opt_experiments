# amortized_opt_experiments

**TO-DO:**
- Tune hyperparameters and try to get fully amortized opt model to work
- Implement efficient way to get optimal action sequences to train fully amortized opt network with mean squared error
  - To do the above, we may need gradient descent to work without warm-start
  - If this is difficult, just use PPO agent(cheating)
